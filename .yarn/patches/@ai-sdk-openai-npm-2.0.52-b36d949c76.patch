diff --git a/dist/index.js b/dist/index.js
index cc6652c4e7f32878a64a2614115bf7eeb3b7c890..76e989017549c89b45d633525efb1f318026d9b2 100644
--- a/dist/index.js
+++ b/dist/index.js
@@ -274,6 +274,7 @@ var openaiChatResponseSchema = (0, import_provider_utils3.lazyValidator)(
           message: import_v42.z.object({
             role: import_v42.z.literal("assistant").nullish(),
             content: import_v42.z.string().nullish(),
+            reasoning_content: import_v42.z.string().nullish(),
             tool_calls: import_v42.z.array(
               import_v42.z.object({
                 id: import_v42.z.string().nullish(),
@@ -340,6 +341,7 @@ var openaiChatChunkSchema = (0, import_provider_utils3.lazyValidator)(
             delta: import_v42.z.object({
               role: import_v42.z.enum(["assistant"]).nullish(),
               content: import_v42.z.string().nullish(),
+              reasoning_content: import_v42.z.string().nullish(),
               tool_calls: import_v42.z.array(
                 import_v42.z.object({
                   index: import_v42.z.number(),
@@ -785,6 +787,14 @@ var OpenAIChatLanguageModel = class {
     if (text != null && text.length > 0) {
       content.push({ type: "text", text });
     }
+    const reasoning =
+      choice.message.reasoning_content;
+    if (reasoning != null && reasoning.length > 0) {
+      content.push({
+        type: 'reasoning',
+        text: reasoning,
+      });
+    }
     for (const toolCall of (_a = choice.message.tool_calls) != null ? _a : []) {
       content.push({
         type: "tool-call",
@@ -866,6 +876,7 @@ var OpenAIChatLanguageModel = class {
     };
     let isFirstChunk = true;
     let isActiveText = false;
+    let isActiveReasoning = false;
     const providerMetadata = { openai: {} };
     return {
       stream: response.pipeThrough(
@@ -920,6 +931,22 @@ var OpenAIChatLanguageModel = class {
               return;
             }
             const delta = choice.delta;
+            const reasoningContent = delta.reasoning_content;
+            if (reasoningContent) {
+              if (!isActiveReasoning) {
+                controller.enqueue({
+                  type: 'reasoning-start',
+                  id: 'reasoning-0',
+                });
+                isActiveReasoning = true;
+              }
+
+              controller.enqueue({
+                type: 'reasoning-delta',
+                id: 'reasoning-0',
+                delta: reasoningContent,
+              });
+            }
             if (delta.content != null) {
               if (!isActiveText) {
                 controller.enqueue({ type: "text-start", id: "0" });
@@ -1032,6 +1059,9 @@ var OpenAIChatLanguageModel = class {
             }
           },
           flush(controller) {
+            if (isActiveReasoning) {
+              controller.enqueue({ type: 'reasoning-end', id: 'reasoning-0' });
+            }
             if (isActiveText) {
               controller.enqueue({ type: "text-end", id: "0" });
             }
